{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4967edb",
   "metadata": {},
   "source": [
    "## 🧠 Arquitectura completa del modelo — `SmallCNN_Res`\n",
    "\n",
    "Este modelo está formado por **bloques convolucionales residuales** que extraen características visuales a diferentes escalas,  \n",
    "y una **parte densa final (clasificador)** que convierte esas características en una decisión binaria (*Benign / Malignant*).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 🧩 Arquitectura del modelo\n",
    "\n",
    "#### 🖼 Entrada  \n",
    "**Imagen RGB:** `[3 × 224 × 224]`\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧱 Bloque 1 — ResidualBlock(3 → 64)\n",
    "- Conv2d(3, 64, kernel_size=3, padding=1)  \n",
    "- BatchNorm2d(64)  \n",
    "- SiLU  \n",
    "- Conv2d(64, 64, kernel_size=3, padding=1)  \n",
    "- BatchNorm2d(64)  \n",
    "- SiLU  \n",
    "- Dropout2d(0.20)  \n",
    "- Residual (1×1 conv si cambia canales)  \n",
    "- SiLU  \n",
    "- MaxPool2d(2,2)  \n",
    "📏 **Salida:** `[64 × 112 × 112]`\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧱 Bloque 2 — ResidualBlock(64 → 128)\n",
    "- Conv2d(64, 128, kernel_size=3, padding=1)  \n",
    "- BatchNorm2d(128)  \n",
    "- SiLU  \n",
    "- Conv2d(128, 128, kernel_size=3, padding=1)  \n",
    "- BatchNorm2d(128)  \n",
    "- SiLU  \n",
    "- Dropout2d(0.20)  \n",
    "- Residual (1×1 conv)  \n",
    "- SiLU  \n",
    "- MaxPool2d(2,2)  \n",
    "📏 **Salida:** `[128 × 56 × 56]`\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧱 Bloque 3 — ResidualBlock(128 → 256)\n",
    "- Conv2d(128, 256, kernel_size=3, padding=1)  \n",
    "- BatchNorm2d(256)  \n",
    "- SiLU  \n",
    "- Conv2d(256, 256, kernel_size=3, padding=1)  \n",
    "- BatchNorm2d(256)  \n",
    "- SiLU  \n",
    "- Dropout2d(0.20)  \n",
    "- Residual (1×1 conv)  \n",
    "- SiLU  \n",
    "- MaxPool2d(2,2)  \n",
    "📏 **Salida:** `[256 × 28 × 28]`\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧱 Bloque 4 — ResidualBlock(256 → 256)\n",
    "- Conv2d(256, 256, kernel_size=3, padding=1)  \n",
    "- BatchNorm2d(256)  \n",
    "- SiLU  \n",
    "- Conv2d(256, 256, kernel_size=3, padding=1)  \n",
    "- BatchNorm2d(256)  \n",
    "- SiLU  \n",
    "- Dropout2d(0.20)  \n",
    "- Residual (sin proyección)  \n",
    "- SiLU  \n",
    "- MaxPool2d(2,2)  \n",
    "📏 **Salida:** `[256 × 14 × 14]`\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔄 Global Average Pooling\n",
    "- AdaptiveAvgPool2d((1,1))  \n",
    "📏 **Salida:** `[256 × 1 × 1]`\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧠 Clasificador (Fully Connected)\n",
    "- Flatten() → `[256]`  \n",
    "- Linear(256 → 128)  \n",
    "- SiLU  \n",
    "- Dropout(0.50)  \n",
    "- Linear(128 → 2)  \n",
    "\n",
    "📤 **Salida final:** `[2]`  \n",
    "*(Probabilidades: Benign / Malignant)*\n",
    "\n",
    "---\n",
    "\n",
    "### 💬 Interpretación general\n",
    "\n",
    "| Etapa | Tipo de capa | Tamaño de salida | Descripción |\n",
    "|:------|:--------------|:----------------:|:-------------|\n",
    "| Entrada | Imagen RGB | [3×224×224] | Imagen normalizada de entrada |\n",
    "| Bloque 1 | Residual conv | [64×112×112] | Detecta bordes, colores y texturas básicas |\n",
    "| Bloque 2 | Residual conv | [128×56×56] | Aprende formas intermedias y estructuras |\n",
    "| Bloque 3 | Residual conv | [256×28×28] | Capta regiones más amplias y patrones complejos |\n",
    "| Bloque 4 | Residual conv | [256×14×14] | Refina las características más profundas |\n",
    "| GAP | Global Avg Pool | [256×1×1] | Resume cada mapa de activación a un valor medio |\n",
    "| FC1 | Densa | [128] | Combina características extraídas |\n",
    "| FC2 | Densa (salida) | [2] | Clasifica en Benigno / Maligno |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ Resumen técnico\n",
    "\n",
    "- 🔹 **Capas convolucionales totales:** 8 (2 por bloque × 4 bloques)  \n",
    "- 🔹 **Capas residuales:** 4 (cada una con posible proyección 1×1)  \n",
    "- 🔹 **Capas densas:** 2  \n",
    "- 🔹 **Funciones de activación:** `SiLU` (suave y estable, ideal para evitar saturación)  \n",
    "- 🔹 **Regularización:** `Dropout(0.20)` en convs y `Dropout(0.50)` en FC  \n",
    "- 🔹 **Tamaño de entrada:** 224×224 píxeles  \n",
    "- 🔹 **Tamaño de salida:** 2 neuronas (clasificación binaria)  \n",
    "- 🔹 **Parámetros entrenables aprox.:** entre **3,5 y 4 millones**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 Resumen conceptual\n",
    "\n",
    "Este modelo combina:\n",
    "- **Bloques residuales profundos**, que facilitan el flujo del gradiente y reducen el sobreajuste.  \n",
    "- **Capas convolucionales dobles**, que permiten extraer rasgos jerárquicos complejos.  \n",
    "- **Pooling progresivo**, que reduce la dimensionalidad manteniendo la información esencial.  \n",
    "- **Un clasificador totalmente conectado**, que interpreta las representaciones y decide si la lesión es benigna o maligna.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ En resumen\n",
    "\n",
    "Tu `SmallCNN_Res` es una CNN **profunda, eficiente y con buena capacidad de generalización**,  \n",
    "capaz de analizar patrones complejos en imágenes dermatoscópicas y **distinguir entre melanomas malignos y lesiones benignas**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195734c3",
   "metadata": {},
   "source": [
    "## 🧩 Celda 1 – Configuración inicial\n",
    "\n",
    "Define todas las **importaciones, rutas y parámetros globales** del proyecto:\n",
    "- Establece las carpetas de trabajo (`train`, `val`, `test`).\n",
    "- Fija las **semillas aleatorias** para asegurar reproducibilidad.\n",
    "- Configura el **dispositivo de entrenamiento** (en este caso, CPU).\n",
    "- Define hiperparámetros como `BATCH`, `EPOCHS`, `LR` y el tamaño de imagen.\n",
    "\n",
    "> 💡 Esta celda no genera resultados visibles, pero es clave para mantener consistencia y evitar comportamientos aleatorios en el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5748101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\proyectos\\Caso_aprendizaje-Melanomas\\data\\raw\\train exists: True\n",
      "D:\\proyectos\\Caso_aprendizaje-Melanomas\\data\\raw\\val exists: True\n",
      "D:\\proyectos\\Caso_aprendizaje-Melanomas\\data\\raw\\test exists: True\n",
      "Device for training: cpu\n",
      "CPU threads: 7\n"
     ]
    }
   ],
   "source": [
    "# === Celda 1: Imports, rutas, device y parámetros (CPU) ===\n",
    "from pathlib import Path\n",
    "import os, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# ---- Rutas (ajústalas si hace falta) ----\n",
    "DATA_DIR = Path(r\"D:/proyectos/Caso_aprendizaje-Melanomas/data/raw\")\n",
    "TRAIN_DIR = DATA_DIR / \"train\"\n",
    "VAL_DIR   = DATA_DIR / \"val\"\n",
    "TEST_DIR  = DATA_DIR / \"test\"\n",
    "\n",
    "for p in (TRAIN_DIR, VAL_DIR, TEST_DIR):\n",
    "    print(p, \"exists:\", p.exists())\n",
    "\n",
    "# ---- Semillas fijas ----\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# ---- Device (solo CPU) + optimizaciones para CPU ----\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Device for training:\", device)\n",
    "\n",
    "# Usa la mayoría de núcleos para acelerar en CPU\n",
    "num_threads = max(1, (os.cpu_count() or 4) - 1)\n",
    "torch.set_num_threads(num_threads)\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")  # mejora BLAS en CPU modernas\n",
    "except Exception:\n",
    "    pass\n",
    "print(f\"CPU threads: {num_threads}\")\n",
    "\n",
    "# Desactiva flags de CUDA (no aplican en CPU)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ---- Parámetros de datos/entreno (pensados para CPU) ----\n",
    "CLASSES = 2\n",
    "ROWS = COLS = 224        # puedes subir a 256 si te cabe en RAM y va fluido\n",
    "BATCH = 16               # en CPU suele aguantar más batch que tu GPU de 4GB\n",
    "EPOCHS = 20              # más épocas para apretar el fine-tune\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 4          # en CPU paraleliza carga de datos (prueba 4–8 según equipo)\n",
    "PIN_MEMORY = False       # en CPU no hace falta\n",
    "USE_AMP = False          # AMP solo aporta en GPU\n",
    "\n",
    "# ---- Normalización (ImageNet) ----\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a175753",
   "metadata": {},
   "source": [
    "## 🧠 Celda 2 – Transformaciones y carga de datos\n",
    "\n",
    "Aplica un **tratamiento y aumento de datos (data augmentation)** moderado para el conjunto de entrenamiento:\n",
    "- Rotaciones, volteos, recortes aleatorios, ajustes de brillo y contraste.\n",
    "- Normalización según los valores de *ImageNet*.\n",
    "- Balancea las clases usando un **WeightedRandomSampler**, para evitar que la clase \"Benign\" domine.\n",
    "\n",
    "> 📊 El objetivo es que el modelo vea imágenes variadas de las lesiones y aprenda a reconocer patrones robustos, evitando el sobreajuste a casos muy concretos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262abd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['Benign', 'Malignant']\n",
      "Class counts: [5346 4752] -> weights: [0.0002 0.0002]\n",
      "Clases (dataset real): ['Benign', 'Malignant']\n",
      "⚙️ Precaching TRAIN (primera vez)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precacheando train: 100%|██████████| 10098/10098 [09:45<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️ Precaching VAL (primera vez)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precacheando val: 100%|██████████| 1781/1781 [01:45<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features listas en memoria.\n",
      "✅ DataLoaders listos.\n",
      "   Train: 10098 imgs | Val: 1781 imgs\n"
     ]
    }
   ],
   "source": [
    "# === Celda 2: Features + Dataset con features + Transforms + Pesos + Caché + DataLoaders ===\n",
    "# Requisitos previos en Celda 1:\n",
    "# DATA_DIR, TRAIN_DIR, VAL_DIR, CLASSES, ROWS, COLS, BATCH, NUM_WORKERS, PIN_MEMORY, IMAGENET_MEAN, IMAGENET_STD\n",
    "\n",
    "# ------------------ Imports base ------------------\n",
    "import os, json, time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import functional as TF\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- libs para features ---\n",
    "import cv2\n",
    "from skimage import morphology, measure, color, filters\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 2.5  EXTRACCIÓN DE FEATURES (segmentación + morfología + color)\n",
    "# ======================================================================\n",
    "def largest_component(mask: np.ndarray) -> np.ndarray:\n",
    "    labeled = measure.label(mask, connectivity=2)\n",
    "    if labeled.max() == 0:\n",
    "        return mask\n",
    "    counts = np.bincount(labeled.ravel())\n",
    "    counts[0] = 0\n",
    "    keep = counts.argmax()\n",
    "    return (labeled == keep).astype(np.uint8)\n",
    "\n",
    "def lesion_mask_binarize(img_bgr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Segmentación rápida basada en V (HSV) + Otsu + morfología.\"\"\"\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    v   = hsv[...,2]\n",
    "    v_blur = cv2.GaussianBlur(v, (5,5), 0)\n",
    "    thr = filters.threshold_otsu(v_blur)\n",
    "    mask = (v_blur < thr).astype(np.uint8)  # lesión suele ser más oscura\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE,\n",
    "                            cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7)), iterations=2)\n",
    "    mask = morphology.remove_small_objects(mask.astype(bool), min_size=200).astype(np.uint8)\n",
    "    mask = morphology.remove_small_holes(mask.astype(bool), area_threshold=200).astype(np.uint8)\n",
    "    mask = largest_component(mask)\n",
    "    return mask\n",
    "\n",
    "def symmetry_scores(mask: np.ndarray) -> tuple[float,float]:\n",
    "    \"\"\"Asimetría izquierda-derecha y arriba-abajo (IoU; 1=simétrico).\"\"\"\n",
    "    h, w = mask.shape\n",
    "    left  = mask[:, :w//2]\n",
    "    right = np.fliplr(mask[:, w - w//2:])\n",
    "    top   = mask[:h//2, :]\n",
    "    bot   = np.flipud(mask[h - h//2:, :])\n",
    "\n",
    "    def iou(a,b):\n",
    "        inter = np.logical_and(a,b).sum()\n",
    "        union = np.logical_or(a,b).sum()\n",
    "        return inter/union if union>0 else 0.0\n",
    "\n",
    "    return iou(left, right), iou(top, bot)\n",
    "\n",
    "def color_features(img_bgr: np.ndarray, mask: np.ndarray, k_colors: int = 3) -> dict:\n",
    "    \"\"\"Medias/desv de HSV en la máscara + diversidad de color (KMeans en S,V).\"\"\"\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    m = mask.astype(bool)\n",
    "    if m.sum() == 0:\n",
    "        return {k:0.0 for k in [\"h_mean\",\"h_std\",\"s_mean\",\"s_std\",\"v_mean\",\"v_std\",\"color_entropy\",\"kspread\"]}\n",
    "\n",
    "    H = hsv[...,0][m].astype(np.float32)         # 0..180 en OpenCV\n",
    "    S = hsv[...,1][m].astype(np.float32)/255.0\n",
    "    V = hsv[...,2][m].astype(np.float32)/255.0\n",
    "\n",
    "    feats = {\n",
    "        \"h_mean\": float(H.mean()), \"h_std\": float(H.std()),\n",
    "        \"s_mean\": float(S.mean()), \"s_std\": float(S.std()),\n",
    "        \"v_mean\": float(V.mean()), \"v_std\": float(V.std()),\n",
    "    }\n",
    "\n",
    "    sv = np.stack([S, V], axis=1)\n",
    "    k = min(k_colors, len(sv))\n",
    "    if k >= 2:\n",
    "        km = KMeans(n_clusters=k, n_init=5, random_state=42)\n",
    "        labels = km.fit_predict(sv)\n",
    "        counts = np.bincount(labels, minlength=k).astype(np.float32)\n",
    "        p = counts / counts.sum()\n",
    "        entropy = -np.sum(p * np.log(p + 1e-12))\n",
    "        centers = km.cluster_centers_\n",
    "        kspread = float(np.linalg.norm(centers.max(0) - centers.min(0)))\n",
    "        feats[\"color_entropy\"] = float(entropy)\n",
    "        feats[\"kspread\"] = kspread\n",
    "    else:\n",
    "        feats[\"color_entropy\"] = 0.0\n",
    "        feats[\"kspread\"] = 0.0\n",
    "\n",
    "    return feats\n",
    "\n",
    "def shape_features(mask: np.ndarray) -> dict:\n",
    "    \"\"\"Área relativa, perímetro relativo, circularidad, irregularidad, excentricidad.\"\"\"\n",
    "    m = mask.astype(bool)\n",
    "    area = m.sum()\n",
    "    if area == 0:\n",
    "        return {k:0.0 for k in [\n",
    "            \"area_rel\",\"perim_rel\",\"circularity\",\"irregularity\",\"eccentricity\",\"sym_lr\",\"sym_tb\"\n",
    "        ]}\n",
    "    h, w = m.shape\n",
    "\n",
    "    # ✅ skimage ≥0.20 usa 'neighborhood'; algunas versiones antiguas aceptaban 'neighbourhood'\n",
    "    try:\n",
    "        perim = measure.perimeter(m, neighborhood=8)\n",
    "    except TypeError:\n",
    "        # Fallback para versiones antiguas (por si acaso)\n",
    "        perim = measure.perimeter(m, neighbourhood=8)\n",
    "\n",
    "    area_rel  = area / (h*w)\n",
    "    perim_rel = perim / (h+w)\n",
    "    circularity = (4*np.pi*area) / (perim**2 + 1e-12)\n",
    "    irregularity = (perim**2) / (4*np.pi*area + 1e-12)\n",
    "\n",
    "    props = measure.regionprops(m.astype(np.uint8))[0]\n",
    "    eccentricity = float(props.eccentricity)\n",
    "\n",
    "    sym_lr, sym_tb = symmetry_scores(mask)\n",
    "    return {\n",
    "        \"area_rel\": float(area_rel),\n",
    "        \"perim_rel\": float(perim_rel),\n",
    "        \"circularity\": float(circularity),\n",
    "        \"irregularity\": float(irregularity),\n",
    "        \"eccentricity\": float(eccentricity),\n",
    "        \"sym_lr\": float(sym_lr),\n",
    "        \"sym_tb\": float(sym_tb),\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_features_from_path(img_path: str) -> tuple[np.ndarray, dict, np.ndarray]:\n",
    "    \"\"\"Devuelve (img_bgr, dict_features, mask).\"\"\"\n",
    "    img_bgr = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "    if img_bgr is None:\n",
    "        raise FileNotFoundError(img_path)\n",
    "    mask = lesion_mask_binarize(img_bgr)\n",
    "    f_shape = shape_features(mask)\n",
    "    f_color = color_features(img_bgr, mask, k_colors=3)\n",
    "    feats = {**f_shape, **f_color}\n",
    "    return img_bgr, feats, mask\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 2.6  DATASET que añade vector de features al sample\n",
    "# ======================================================================\n",
    "FEATURE_KEYS = [\n",
    "    \"area_rel\",\"perim_rel\",\"circularity\",\"irregularity\",\"eccentricity\",\n",
    "    \"sym_lr\",\"sym_tb\",\"h_mean\",\"h_std\",\"s_mean\",\"s_std\",\"v_mean\",\"v_std\",\n",
    "    \"color_entropy\",\"kspread\"\n",
    "]\n",
    "\n",
    "class ImageFolderWithFeatures(ImageFolder):\n",
    "    def __init__(self, root, transform=None, cache=True):\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.cache = cache\n",
    "        self._cache = {}\n",
    "\n",
    "    def _get_feats(self, path):\n",
    "        if self.cache and path in self._cache:\n",
    "            return self._cache[path]\n",
    "        _, feats, _ = extract_features_from_path(path)\n",
    "        x = np.array([feats[k] for k in FEATURE_KEYS], dtype=np.float32)\n",
    "        if self.cache:\n",
    "            self._cache[path] = x\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        sample = self.loader(path)  # PIL\n",
    "        img = self.transform(sample) if self.transform is not None else TF.to_tensor(sample)\n",
    "        feats = torch.from_numpy(self._get_feats(path))  # [F]\n",
    "        return img, target, feats\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 2.0  TRANSFORMS + pesos por clase (antes de DataLoaders)\n",
    "# ======================================================================\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((ROWS, COLS), scale=(0.70, 1.00), ratio=(0.90, 1.10)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15, fill=(128, 128, 128)),\n",
    "    transforms.ColorJitter(brightness=0.20, contrast=0.20, saturation=0.10, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    transforms.RandomErasing(p=0.25, scale=(0.02, 0.08), ratio=(0.3, 3.3)),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((ROWS, COLS)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# Descubrir clases/pesos\n",
    "_tmp_ds = datasets.ImageFolder(TRAIN_DIR)\n",
    "print(\"Clases detectadas:\", _tmp_ds.classes)\n",
    "assert len(_tmp_ds.classes) == CLASSES, f\"Esperaba {CLASSES} clases, encontré {len(_tmp_ds.classes)}.\"\n",
    "targets_for_weights = np.array([y for _, y in _tmp_ds.samples])\n",
    "CLASS_COUNTS_NP  = np.bincount(targets_for_weights, minlength=CLASSES)\n",
    "CLASS_WEIGHTS_NP = 1.0 / (CLASS_COUNTS_NP + 1e-6)\n",
    "CLASSES_LIST     = _tmp_ds.classes\n",
    "print(\"Class counts:\", CLASS_COUNTS_NP, \"-> weights:\", np.round(CLASS_WEIGHTS_NP, 4))\n",
    "del _tmp_ds\n",
    "\n",
    "# ======================================================================\n",
    "# 2.3  Crear DATASETS con features\n",
    "# ======================================================================\n",
    "train_ds = ImageFolderWithFeatures(TRAIN_DIR, transform=train_tfms, cache=True)\n",
    "val_ds   = ImageFolderWithFeatures(VAL_DIR,   transform=val_tfms,   cache=True)\n",
    "print(\"Clases (dataset real):\", train_ds.classes)\n",
    "\n",
    "# ======================================================================\n",
    "# 2.7  CACHÉ de features (cargar si existe; si no, precalcular y guardar)\n",
    "# ======================================================================\n",
    "CACHE_DIR = DATA_DIR / \"_feats_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "def precache_features(ds):\n",
    "    for path, _ in tqdm(ds.samples, total=len(ds.samples), desc=f\"Precacheando {os.path.basename(ds.root)}\"):\n",
    "        _ = ds._get_feats(path)\n",
    "\n",
    "def save_cache(ds, out_json):\n",
    "    serial = {p: ds._cache[p].tolist() for p,_ in ds.samples if p in ds._cache}\n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(serial, f)\n",
    "\n",
    "def load_cache(ds, in_json):\n",
    "    if not os.path.exists(in_json):\n",
    "        return False\n",
    "    with open(in_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    ds._cache.update({k: np.array(v, dtype=np.float32) for k, v in data.items()})\n",
    "    print(f\"Cache cargada desde: {in_json} ({len(data)} entradas)\")\n",
    "    return True\n",
    "\n",
    "loaded_train = load_cache(train_ds, str(CACHE_DIR / \"train_feats.json\"))\n",
    "loaded_val   = load_cache(val_ds,   str(CACHE_DIR / \"val_feats.json\"))\n",
    "\n",
    "if not loaded_train:\n",
    "    print(\"⚙️ Precaching TRAIN (primera vez)...\")\n",
    "    precache_features(train_ds)\n",
    "    save_cache(train_ds, str(CACHE_DIR / \"train_feats.json\"))\n",
    "\n",
    "if not loaded_val:\n",
    "    print(\"⚙️ Precaching VAL (primera vez)...\")\n",
    "    precache_features(val_ds)\n",
    "    save_cache(val_ds, str(CACHE_DIR / \"val_feats.json\"))\n",
    "\n",
    "print(\"✅ Features listas en memoria.\")\n",
    "\n",
    "# ======================================================================\n",
    "# 2.8  DATALOADERS balanceados (con collate que incluye features)\n",
    "# ======================================================================\n",
    "targets = np.array([y for _, y in train_ds.samples])\n",
    "sample_weights = CLASS_WEIGHTS_NP[targets]\n",
    "sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                num_samples=len(sample_weights),\n",
    "                                replacement=True)\n",
    "\n",
    "def collate_with_feats(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch], dim=0)\n",
    "    ys   = torch.tensor([b[1] for b in batch], dtype=torch.long)\n",
    "    fs   = torch.stack([b[2] for b in batch], dim=0)\n",
    "    return imgs, ys, fs\n",
    "\n",
    "persistent = True if NUM_WORKERS and NUM_WORKERS > 0 else False\n",
    "\n",
    "train_dl = DataLoader(train_ds,\n",
    "                      batch_size=BATCH,\n",
    "                      sampler=sampler,\n",
    "                      num_workers=NUM_WORKERS,\n",
    "                      pin_memory=PIN_MEMORY,\n",
    "                      persistent_workers=persistent,\n",
    "                      collate_fn=collate_with_feats)\n",
    "\n",
    "val_dl = DataLoader(val_ds,\n",
    "                    batch_size=BATCH,\n",
    "                    shuffle=False,\n",
    "                    num_workers=NUM_WORKERS,\n",
    "                    pin_memory=PIN_MEMORY,\n",
    "                    persistent_workers=persistent,\n",
    "                    collate_fn=collate_with_feats)\n",
    "\n",
    "print(\"✅ DataLoaders listos.\")\n",
    "print(f\"   Train: {len(train_ds)} imgs | Val: {len(val_ds)} imgs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f01980a",
   "metadata": {},
   "source": [
    "## 🔬 Celda 3 – Definición del modelo convolucional mejorado\n",
    "\n",
    "Define la arquitectura `SmallCNN_Res_Fusion`, basada en **bloques residuales**:\n",
    "- 4 bloques de convoluciones con conexiones *skip* para estabilidad.\n",
    "- Función de activación *SiLU* (más suave que ReLU).\n",
    "- Promedio global (GAP) + capa totalmente conectada con fusión de features.\n",
    "\n",
    "> 💪 Este modelo es más profundo y estable que la versión simple.  \n",
    "> Gracias a las conexiones residuales, se entrena mejor incluso con conjuntos de datos limitados y capta texturas y estructuras más complejas de la piel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6836a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros entrenables (fusión): 2,404,098\n"
     ]
    }
   ],
   "source": [
    "# === Celda 3: Modelo CNN + FUSIÓN de features (doble conv + residual) ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "\n",
    "# Nº de features adicionales (definido por tu Celda 2.6)\n",
    "N_FEATS = len(FEATURE_KEYS)  # p.ej., 15\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Conv3x3 -> BN -> SiLU -> Conv3x3 -> BN -> SiLU -> Dropout2d\"\"\"\n",
    "    def __init__(self, in_ch, out_ch, drop=0.20):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.SiLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_ch, out_ch, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.SiLU(inplace=True),\n",
    "\n",
    "            nn.Dropout2d(drop),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    x ──► DoubleConv ──► + (proyección 1x1 si cambia canal) ──► SiLU ──► MaxPool(2)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, drop=0.20):\n",
    "        super().__init__()\n",
    "        self.double = DoubleConv(in_ch, out_ch, drop=drop)\n",
    "        self.proj: Optional[nn.Module] = None\n",
    "        if in_ch != out_ch:\n",
    "            self.proj = nn.Sequential(\n",
    "                nn.Conv2d(in_ch, out_ch, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_ch)\n",
    "            )\n",
    "        self.act  = nn.SiLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.double(x)\n",
    "        skip = x if self.proj is None else self.proj(x)\n",
    "        y = self.act(y + skip)\n",
    "        y = self.pool(y)\n",
    "        return y\n",
    "\n",
    "class SmallCNN_Res_Fusion(nn.Module):\n",
    "    \"\"\"\n",
    "    4 bloques residuales (8 convs): 224→112→56→28→14\n",
    "    GAP -> concat([feat_map, features_extras]) -> MLP -> logits\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, num_classes=2, drop_conv=0.20, drop_fc=0.50, n_feats=N_FEATS):\n",
    "        super().__init__()\n",
    "        self.block1 = ResidualBlock(in_ch,   64,  drop=drop_conv)\n",
    "        self.block2 = ResidualBlock(64,      128, drop=drop_conv)\n",
    "        self.block3 = ResidualBlock(128,     256, drop=drop_conv)\n",
    "        self.block4 = ResidualBlock(256,     256, drop=drop_conv)\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))  # [B,256,1,1]\n",
    "        self.flatten = nn.Flatten()             # -> [B,256]\n",
    "        self.n_feats = n_feats\n",
    "\n",
    "        # Cabeza de fusión: concatena [256] con [n_feats]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(256 + n_feats, 128),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(drop_fc),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "        # Inicialización Kaiming para estabilidad\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, feats):\n",
    "        # x: [B,3,H,W], feats: [B, n_feats]\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.flatten(x)                 # [B,256]\n",
    "        # Asegura tipo/shape de feats\n",
    "        if feats.dim() == 1:\n",
    "            feats = feats.unsqueeze(0)\n",
    "        feats = feats.to(x.dtype)\n",
    "        z = torch.cat([x, feats], dim=1)    # [B, 256+n_feats]\n",
    "        out = self.head(z)                  # [B,num_classes]\n",
    "        return out\n",
    "\n",
    "# Instanciación\n",
    "model = SmallCNN_Res_Fusion(in_ch=3, num_classes=CLASSES,\n",
    "                            drop_conv=0.20, drop_fc=0.50, n_feats=N_FEATS).to(device)\n",
    "params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Parámetros entrenables (fusión): {params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4df2b",
   "metadata": {},
   "source": [
    "## ⚙️ Celda 4 – Definición de la función de pérdida y optimizador\n",
    "\n",
    "- Usa **CrossEntropyLoss** con pesos por clase para corregir el desequilibrio entre \"Benign\" y \"Malignant\".\n",
    "- Emplea el optimizador **AdamW**, que combina Adam con regularización L2 (controla el sobreajuste).\n",
    "- Define la métrica de precisión (`accuracy_from_logits`).\n",
    "\n",
    "> ⚖️ Esta celda ajusta cómo el modelo aprende (descenso del gradiente) y penaliza los errores de forma equilibrada entre las dos clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b7e68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: AdamW | LR = 0.0003 | weight_decay = 0.0001\n"
     ]
    }
   ],
   "source": [
    "# === Celda 4: Loss, optimizador y métrica (CPU) ===\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Toma los pesos de clase desde la Celda 2 (fallback si cambiaste el nombre)\n",
    "_weights_np = globals().get(\"CLASS_WEIGHTS_NP\", globals().get(\"class_weights\", None))\n",
    "assert _weights_np is not None, \"No encuentro CLASS_WEIGHTS_NP ni class_weights (revisa Celda 2).\"\n",
    "\n",
    "w = torch.tensor(_weights_np, dtype=torch.float32, device=device)\n",
    "\n",
    "# Pérdida ponderada + label smoothing suave\n",
    "criterion = nn.CrossEntropyLoss(weight=w, label_smoothing=0.05)\n",
    "\n",
    "# Optimizador con buen decay (mejor que Adam para fine-tune)\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.AdamW(trainable_params, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Métrica principal: accuracy\n",
    "def accuracy_from_logits(logits, targets):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "print(\"Optimizer: AdamW | LR =\", LR, \"| weight_decay =\", WEIGHT_DECAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd593a1",
   "metadata": {},
   "source": [
    "## 🚀 Celda 5 – Entrenamiento y validación\n",
    "\n",
    "Ejecuta el bucle de entrenamiento:\n",
    "1. **Entrena** el modelo sobre `train_dl` durante varias épocas.\n",
    "2. **Evalúa** sobre `val_dl` en cada época.\n",
    "3. Usa **early stopping** si la pérdida de validación deja de mejorar.\n",
    "4. Guarda el mejor modelo (`.pth`) basado en la pérdida mínima.\n",
    "\n",
    "> 📈 Aquí se observa si el modelo realmente aprende:  \n",
    "> - La *pérdida de entrenamiento* debe disminuir progresivamente.  \n",
    "> - La *pérdida de validación* no debe aumentar mucho (evita overfitting).  \n",
    "> - Las *precisiones* de train y val deben estar próximas si el modelo generaliza bien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa59743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\proyectos\\Caso_aprendizaje-Melanomas\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# === Celda 5: Entreno/validación (CPU, sin AMP) — compatible con features ===\n",
    "\n",
    "def _unpack_batch(batch):\n",
    "    # batch puede ser (x,y,f) o (x,y)\n",
    "    if isinstance(batch, (list, tuple)) and len(batch) == 3:\n",
    "        x, y, f = batch\n",
    "    else:\n",
    "        x, y = batch\n",
    "        f = None\n",
    "    return x, y, f\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, clip_grad_norm=1.0, log_every=20):\n",
    "    \"\"\"\n",
    "    Entrena una época completa y muestra progreso por batches.\n",
    "    log_every: muestra info cada N batches.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = total_acc = n = 0\n",
    "    n_batches = len(loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, batch in enumerate(loader):\n",
    "        x, y, f = _unpack_batch(batch)\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        if f is not None: f = f.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x, f) if f is not None else model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "\n",
    "        # (opcional) clipping para estabilidad en CPU\n",
    "        if clip_grad_norm and clip_grad_norm > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc  += accuracy_from_logits(logits, y)\n",
    "        n += 1\n",
    "\n",
    "        # 🔹 Mostrar progreso cada log_every batches\n",
    "        if (i + 1) % log_every == 0 or (i + 1) == n_batches:\n",
    "            pct = 100 * (i + 1) / n_batches\n",
    "            avg_loss = total_loss / n\n",
    "            avg_acc  = total_acc / n\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"[Batch {i+1:4d}/{n_batches}] {pct:5.1f}% | Loss={avg_loss:.4f} | \"\n",
    "                  f\"Acc={avg_acc:.4f} | Tiempo={elapsed:.1f}s\")\n",
    "\n",
    "    epoch_loss = total_loss / max(n, 1)\n",
    "    epoch_acc  = total_acc / max(n, 1)\n",
    "    print(f\"✅ Época completada: loss={epoch_loss:.4f}, acc={epoch_acc:.4f}, \"\n",
    "          f\"duración total={time.time()-start_time:.1f}s\\n\")\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = total_acc = n = 0\n",
    "    for batch in loader:\n",
    "        x, y, f = _unpack_batch(batch)\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        if f is not None: f = f.to(device)\n",
    "\n",
    "        logits = model(x, f) if f is not None else model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc  += accuracy_from_logits(logits, y)\n",
    "        n += 1\n",
    "    return total_loss / max(n, 1), total_acc / max(n, 1)\n",
    "\n",
    "history = {\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n",
    "BEST_PATH = \"smallcnn_res_fusion_cpu_best.pth\"  # nombre coherente con el modelo fusionado\n",
    "\n",
    "# === Scheduler + Early Stopping (usa el optimizer de Celda 4) ===\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "EARLY_PATIENCE = 6\n",
    "no_improve = 0\n",
    "best_val = float('inf')\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_dl, optimizer, criterion, clip_grad_norm=1.0)\n",
    "    va_loss, va_acc = validate(model, val_dl, criterion)\n",
    "\n",
    "    # guarda historial para las curvas\n",
    "    history[\"train_loss\"].append(tr_loss); history[\"train_acc\"].append(tr_acc)\n",
    "    history[\"val_loss\"].append(va_loss);   history[\"val_acc\"].append(va_acc)\n",
    "\n",
    "    # step del scheduler en función de val_loss\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    # guarda mejor checkpoint por val_loss\n",
    "    if va_loss < best_val:\n",
    "        best_val = va_loss\n",
    "        torch.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            \"classes\": CLASSES_LIST if 'CLASSES_LIST' in globals() else None,\n",
    "            \"img_size\": (ROWS, COLS),\n",
    "            \"feature_keys\": FEATURE_KEYS  # para asegurar compatibilidad al cargar\n",
    "        }, BEST_PATH)\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= EARLY_PATIENCE:\n",
    "            print(\"Early stopping 🚦\")\n",
    "            break\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    cur_lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(f\"[{epoch:02d}] train_loss={tr_loss:.4f} acc={tr_acc:.4f} | \"\n",
    "          f\"val_loss={va_loss:.4f} acc={va_acc:.4f} | lr={cur_lr:.2e} | {dt:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba074fdd",
   "metadata": {},
   "source": [
    "## 🧮 Celda 6 – Búsqueda del umbral óptimo\n",
    "\n",
    "Explora diferentes **umbrales de decisión** para clasificar una imagen como “Malignant”.\n",
    "- Calcula F1-score, Recall y Precision para cada umbral.\n",
    "- Escoge el valor que **maximiza el F1-score**, equilibrio entre precisión y sensibilidad.\n",
    "\n",
    "> 🔍 Este paso mejora la clasificación en problemas médicos, donde el objetivo es reducir **falsos negativos** (no pasar por alto melanomas malignos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7345c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 6: Buscar UMBRAL ÓPTIMO en validación (compatible con features) ===\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def _unpack_batch_for_probs(batch):\n",
    "    # batch puede ser (x,y,f) o (x,y)\n",
    "    if isinstance(batch, (list, tuple)) and len(batch) == 3:\n",
    "        x, y, f = batch\n",
    "    else:\n",
    "        x, y = batch\n",
    "        f = None\n",
    "    return x, y, f\n",
    "\n",
    "def collect_probs_labels(model, loader, malignant_idx=1):\n",
    "    \"\"\"Devuelve prob(Malignant) y etiquetas verdaderas desde un loader.\"\"\"\n",
    "    model.eval()\n",
    "    probs, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x, y, f = _unpack_batch_for_probs(batch)\n",
    "            x = x.to(device)\n",
    "            if f is not None:\n",
    "                f = f.to(device)\n",
    "                logits = model(x, f)\n",
    "            else:\n",
    "                logits = model(x)\n",
    "            p = torch.softmax(logits, dim=1)[:, malignant_idx].cpu().numpy()\n",
    "            probs.append(p); labels.append(y.numpy())\n",
    "    return np.concatenate(probs), np.concatenate(labels)\n",
    "\n",
    "# 1) Probabilidades en validación para la clase \"Malignant\" (índice 1)\n",
    "val_probs, val_y = collect_probs_labels(model, val_dl, malignant_idx=1)\n",
    "\n",
    "# 2) Barrido de umbrales\n",
    "ths = np.linspace(0.05, 0.95, 37)\n",
    "f1s, recs, precs = [], [], []\n",
    "best_f1, best_t_f1 = -1.0, 0.5\n",
    "best_rec, best_t_rec = -1.0, 0.5\n",
    "\n",
    "for t in ths:\n",
    "    preds = (val_probs >= t).astype(int)\n",
    "    f1  = f1_score(val_y, preds, pos_label=1, zero_division=0)\n",
    "    rec = recall_score(val_y, preds, pos_label=1, zero_division=0)\n",
    "    pre = precision_score(val_y, preds, pos_label=1, zero_division=0)\n",
    "    f1s.append(f1); recs.append(rec); precs.append(pre)\n",
    "    if f1 > best_f1: best_f1, best_t_f1 = f1, t\n",
    "    if rec > best_rec: best_rec, best_t_rec = rec, t\n",
    "\n",
    "print(f\"▪ Umbral óptimo por F1: {best_t_f1:.2f} | F1={best_f1:.3f}\")\n",
    "print(f\"▪ Umbral que maximiza Recall: {best_t_rec:.2f} | Recall={best_rec:.3f}\")\n",
    "\n",
    "# 3) Elige el criterio principal\n",
    "OPT_THRESH = best_t_f1\n",
    "print(f\"OPT_THRESH = {OPT_THRESH:.2f} (usado por defecto)\")\n",
    "\n",
    "# 4) (Opcional) Visualiza F1/Recall/Precision vs Umbral\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(ths, f1s,  label=\"F1\")\n",
    "plt.plot(ths, recs, label=\"Recall\")\n",
    "plt.plot(ths, precs,label=\"Precision\")\n",
    "plt.axvline(OPT_THRESH, ls=\"--\")\n",
    "plt.xlabel(\"Umbral\"); plt.ylabel(\"Métrica\")\n",
    "plt.title(\"Métricas en Validación vs Umbral\")\n",
    "plt.grid(True, ls=\"--\", alpha=0.5); plt.legend()\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abb4f28",
   "metadata": {},
   "source": [
    "## 🧾 Celda 7 – Evaluación en el conjunto de test\n",
    "\n",
    "Evalúa el rendimiento del modelo final en las imágenes **nunca vistas**:\n",
    "- Calcula la precisión total y por clase.  \n",
    "- Aplica el umbral óptimo obtenido en validación.  \n",
    "\n",
    "> 🧪 Aquí se obtiene la medida real de rendimiento del modelo: cómo se comportaría con casos nuevos fuera del entrenamiento.\n",
    "> Si los resultados de *test* son similares a *val*, el modelo **generaliza correctamente**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 7: Evaluación en test (CPU, compatible con features) ===\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1) Cargar mejor checkpoint\n",
    "ckpt = torch.load(BEST_PATH, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "# 2) Dataset/Dataloader de test (usa tfms de validación y la clase con features)\n",
    "test_ds = ImageFolderWithFeatures(TEST_DIR, transform=val_tfms, cache=True)\n",
    "persistent = True if NUM_WORKERS and NUM_WORKERS > 0 else False\n",
    "\n",
    "# collate igual que en train_dl/val_dl\n",
    "def collate_with_feats(batch):\n",
    "    imgs = torch.stack([b[0] for b in batch], dim=0)\n",
    "    ys   = torch.tensor([b[1] for b in batch], dtype=torch.long)\n",
    "    fs   = torch.stack([b[2] for b in batch], dim=0)\n",
    "    return imgs, ys, fs\n",
    "\n",
    "test_dl = DataLoader(test_ds,\n",
    "                     batch_size=BATCH,\n",
    "                     shuffle=False,\n",
    "                     num_workers=NUM_WORKERS,\n",
    "                     pin_memory=PIN_MEMORY,\n",
    "                     persistent_workers=persistent,\n",
    "                     collate_fn=collate_with_feats)\n",
    "\n",
    "# --- Función auxiliar de desempaquetado ---\n",
    "def _unpack_batch(batch):\n",
    "    if isinstance(batch, (list, tuple)) and len(batch) == 3:\n",
    "        x, y, f = batch\n",
    "    else:\n",
    "        x, y = batch\n",
    "        f = None\n",
    "    return x, y, f\n",
    "\n",
    "# --- Evaluación estándar (argmax, sin umbral) ---\n",
    "@torch.no_grad()\n",
    "def evaluate_loader_argmax(model, loader):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    per_class = Counter(); per_class_correct = Counter()\n",
    "\n",
    "    for batch in loader:\n",
    "        x, y, f = _unpack_batch(batch)\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        if f is not None: f = f.to(device)\n",
    "\n",
    "        logits = model(x, f) if f is not None else model(x)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total   += y.numel()\n",
    "\n",
    "        for yi, pi in zip(y.tolist(), preds.tolist()):\n",
    "            per_class[yi] += 1\n",
    "            if yi == pi:\n",
    "                per_class_correct[yi] += 1\n",
    "\n",
    "    acc = correct / total if total else 0.0\n",
    "    return acc, per_class, per_class_correct\n",
    "\n",
    "# --- Evaluación con umbral óptimo (p(Malignant) >= thr) ---\n",
    "@torch.no_grad()\n",
    "def evaluate_loader_with_threshold(model, loader, malignant_idx=1, thr=0.5):\n",
    "    model.eval()\n",
    "    total, correct = 0, 0\n",
    "    for batch in loader:\n",
    "        x, y, f = _unpack_batch(batch)\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        if f is not None: f = f.to(device)\n",
    "\n",
    "        logits = model(x, f) if f is not None else model(x)\n",
    "        probs = torch.softmax(logits, dim=1)[:, malignant_idx]\n",
    "        preds = (probs >= thr).long()\n",
    "        correct += (preds == y).sum().item()\n",
    "        total   += y.numel()\n",
    "    return correct / total if total else 0.0\n",
    "\n",
    "# 3) Evaluación y reporte por clase (argmax)\n",
    "test_acc, counts, rights = evaluate_loader_argmax(model, test_dl)\n",
    "print(f\"Test accuracy (argmax): {test_acc:.4f}\")\n",
    "idx2class = {i: c for i, c in enumerate(test_ds.classes)}\n",
    "for i in range(len(test_ds.classes)):\n",
    "    n = counts[i]; ok = rights[i]; name = idx2class[i]\n",
    "    if n > 0:\n",
    "        print(f\"  {name:>10s}: {ok}/{n} ({ok/n:.3f})\")\n",
    "    else:\n",
    "        print(f\"  {name:>10s}: 0/0 (N/A)\")\n",
    "\n",
    "# 4) (opcional) Evaluación con umbral óptimo\n",
    "if 'OPT_THRESH' in globals():\n",
    "    acc_thr = evaluate_loader_with_threshold(model, test_dl,\n",
    "                                             malignant_idx=1, thr=OPT_THRESH)\n",
    "    print(f\"\\nTest accuracy (umbral óptimo={OPT_THRESH:.2f}): {acc_thr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec40733",
   "metadata": {},
   "source": [
    "## 📋 Interpretación del reporte con umbral óptimo\n",
    "\n",
    "Esta celda evalúa el modelo final usando el **umbral de decisión ajustado (`OPT_THRESH`)**, obtenido en la celda anterior para maximizar el equilibrio entre *precisión* y *recall*.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 Qué hace el código\n",
    "1. **`collect_probs_labels`**: calcula las probabilidades de que cada imagen pertenezca a la clase *Malignant*.\n",
    "2. **`(test_probs >= OPT_THRESH)`**: convierte esas probabilidades en predicciones binarias (`0 = Benign`, `1 = Malignant`).\n",
    "3. **`classification_report`**: genera métricas detalladas para cada clase.\n",
    "4. **`confusion_matrix`**: muestra cuántas predicciones fueron correctas o incorrectas en cada categoría.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Cómo interpretar el reporte\n",
    "\n",
    "El `classification_report` devuelve cuatro métricas principales para cada clase:\n",
    "\n",
    "| Métrica | Significado | Interpretación |\n",
    "|:---------|:-------------|:----------------|\n",
    "| **Precision** | De todos los casos que el modelo predijo como *Malignant*, cuántos lo eran realmente. | Alta precisión = pocos falsos positivos. |\n",
    "| **Recall (Sensibilidad)** | De todos los *Malignant* reales, cuántos detectó el modelo. | Alta sensibilidad = pocos falsos negativos. |\n",
    "| **F1-score** | Media armónica entre precisión y recall. | Resume el equilibrio entre ambas métricas. |\n",
    "| **Support** | Número real de ejemplos de esa clase en el conjunto de test. | Muestra el tamaño de la muestra. |\n",
    "\n",
    "Además, el bloque final del reporte muestra:\n",
    "- **Accuracy global**: porcentaje total de aciertos del modelo.  \n",
    "- **Macro avg**: media simple entre ambas clases (sin ponderar).  \n",
    "- **Weighted avg**: media ponderada por la frecuencia de cada clase (más realista si hay desequilibrio).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔲 Cómo leer la matriz de confusión\n",
    "\n",
    "La matriz se organiza así:\n",
    "\n",
    "|                 | Predicho Benign | Predicho Malignant |\n",
    "|:----------------|:----------------|:-------------------|\n",
    "| **Real Benign** | Verdaderos negativos (TN) | Falsos positivos (FP) |\n",
    "| **Real Malignant** | Falsos negativos (FN) | Verdaderos positivos (TP) |\n",
    "\n",
    "- **Diagonal principal (TN + TP)** → casos correctamente clasificados.  \n",
    "- **Fuera de la diagonal (FP + FN)** → errores del modelo.  \n",
    "\n",
    "> 💡 En diagnóstico médico, es especialmente importante **minimizar los falsos negativos (FN)**,  \n",
    "> ya que representan casos malignos que el modelo no detectó correctamente.\n",
    "\n",
    "---\n",
    "\n",
    "### 💬 En resumen\n",
    "\n",
    "> Esta evaluación muestra el **rendimiento real del modelo sobre imágenes nuevas**, aplicando el umbral óptimo encontrado.  \n",
    "> Un buen modelo debe mostrar:\n",
    "> - Alta *precision* y *recall* en la clase *Malignant*.\n",
    "> - Un *F1-score* equilibrado entre ambas clases.\n",
    "> - Una matriz de confusión con la mayoría de los valores concentrados en la diagonal principal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluación final con umbral óptimo ===\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_probs, test_y = collect_probs_labels(model, test_dl, malignant_idx=1)\n",
    "test_pred = (test_probs >= OPT_THRESH).astype(int)\n",
    "\n",
    "print(\"\\n📋 Reporte con umbral óptimo:\")\n",
    "print(classification_report(test_y, test_pred, target_names=test_ds.classes))\n",
    "print(\"Matriz de confusión (umbral ajustado):\\n\", confusion_matrix(test_y, test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca969c",
   "metadata": {},
   "source": [
    "## 🎨 Interpretación de la matriz de confusión ajustada\n",
    "\n",
    "Esta celda **no calcula nuevas métricas**, sino que **representa visualmente** la matriz de confusión obtenida en la evaluación final.\n",
    "\n",
    "El objetivo es facilitar la **interpretación visual de los aciertos y errores** del modelo:\n",
    "\n",
    "- El **color más oscuro** en la diagonal indica una mayor cantidad de aciertos.  \n",
    "- Las **celdas fuera de la diagonal** representan errores:\n",
    "  - Falsos positivos (el modelo predijo *Malignant* pero era *Benign*).\n",
    "  - Falsos negativos (el modelo predijo *Benign* pero era *Malignant*).\n",
    "\n",
    "> 💡 En diagnóstico médico, es fundamental que la celda correspondiente a **Malignant → Malignant** (parte inferior derecha) tenga un color intenso,  \n",
    "> ya que eso indica una **alta detección de casos realmente malignos**.\n",
    "\n",
    "Además, esta versión:\n",
    "- Usa un **mapa de color azul (\"Blues\")** para mostrar las intensidades.\n",
    "- Añade **etiquetas numéricas** dentro de cada celda.\n",
    "- Guarda la imagen como `confusion_matrix_adjusted.png` para incluirla en informes o presentaciones.\n",
    "\n",
    "> En resumen, esta celda no cambia los resultados, pero **mejora la comprensión visual** de los aciertos y errores del modelo en el conjunto de test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d700a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Matriz de confusión AJUSTADA (grande y con colores) ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# --- Usa la versión compatible de collect_probs_labels (la que admite f) ---\n",
    "test_probs, test_y = collect_probs_labels(model, test_dl, malignant_idx=1)  # p(Malignant)\n",
    "test_pred = (test_probs >= OPT_THRESH).astype(int)\n",
    "\n",
    "# --- Matriz de confusión ---\n",
    "cm = confusion_matrix(test_y, test_pred)\n",
    "\n",
    "# --- Plot grande y con colorbar ---\n",
    "fig, ax = plt.subplots(figsize=(8.5, 7.5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_ds.classes)\n",
    "disp.plot(cmap=\"Blues\", values_format='d', ax=ax, colorbar=True)\n",
    "\n",
    "ax.set_title(f\"Matriz de Confusión (Test) — Umbral óptimo = {OPT_THRESH:.2f}\",\n",
    "             fontsize=16, pad=12)\n",
    "ax.set_xlabel(\"Predicción\", fontsize=13)\n",
    "ax.set_ylabel(\"Etiqueta real\", fontsize=13)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- (opcional) Guardar a disco ---\n",
    "fig, ax = plt.subplots(figsize=(8.5, 7.5))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_ds.classes)\n",
    "disp.plot(cmap=\"Blues\", values_format='d', ax=ax, colorbar=True)\n",
    "ax.set_title(f\"Matriz de Confusión (Test) — Umbral óptimo = {OPT_THRESH:.2f}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"confusion_matrix_adjusted.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"✅ Guardada en: confusion_matrix_adjusted.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff9306",
   "metadata": {},
   "source": [
    "## 📊 Celda 7.5 – Comparativa y análisis de generalización\n",
    "\n",
    "Muestra un resumen global de métricas (Loss, Accuracy, F1, Recall, Precision) para *train*, *val* y *test*.  \n",
    "También calcula los **gaps de generalización** entre entrenamiento y test.\n",
    "\n",
    "> 💬 Interpretación:\n",
    "> - Si el *gap* entre train y test es **< 2% → excelente generalización**.  \n",
    "> - Entre 2–5% → buena generalización.  \n",
    "> - > 5% → *overfitting*.  \n",
    "> - Gap negativo grande → *underfitting*.  \n",
    ">\n",
    "> El gráfico permite ver si el modelo mantiene un rendimiento estable fuera del conjunto de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6bb9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 7.5: Evaluación global y generalización del modelo ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "# --- Métricas finales de entrenamiento ---\n",
    "final_train_loss = history[\"train_loss\"][-1]\n",
    "final_val_loss   = history[\"val_loss\"][-1]\n",
    "final_train_acc  = history[\"train_acc\"][-1]\n",
    "final_val_acc    = history[\"val_acc\"][-1]\n",
    "\n",
    "# --- Métricas de test (usando OPT_THRESH) ---\n",
    "test_probs, test_y = collect_probs_labels(model, test_dl, malignant_idx=1)\n",
    "test_pred = (test_probs >= OPT_THRESH).astype(int)\n",
    "\n",
    "test_acc = np.mean(test_pred == test_y)\n",
    "test_f1  = f1_score(test_y, test_pred, pos_label=1)\n",
    "test_rec = recall_score(test_y, test_pred, pos_label=1)\n",
    "test_pre = precision_score(test_y, test_pred, pos_label=1)\n",
    "\n",
    "# --- Gaps de generalización (diferencias porcentuales) ---\n",
    "gap_train_val  = 100 * (final_train_acc - final_val_acc)\n",
    "gap_train_test = 100 * (final_train_acc - test_acc)\n",
    "\n",
    "# --- Tabla resumen ---\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Conjunto\": [\"Entrenamiento\", \"Validación\", \"Test\"],\n",
    "    \"Loss\": [final_train_loss, final_val_loss, np.nan],\n",
    "    \"Accuracy\": [final_train_acc, final_val_acc, test_acc],\n",
    "    \"F1\": [np.nan, np.nan, test_f1],\n",
    "    \"Recall\": [np.nan, np.nan, test_rec],\n",
    "    \"Precision\": [np.nan, np.nan, test_pre]\n",
    "})\n",
    "\n",
    "display(metrics_df.round(4))\n",
    "\n",
    "# --- Gráfico de barras comparativo ---\n",
    "plt.style.use(\"seaborn-v0_8-muted\")\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sets = [\"Entrenamiento\", \"Validación\", \"Test\"]\n",
    "accs = [final_train_acc, final_val_acc, test_acc]\n",
    "bars = ax.bar(sets, accs, color=[\"#57c057\", \"#c662c1\", \"#1f77b4\"], alpha=0.85)\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_ylabel(\"Accuracy\", fontsize=12)\n",
    "ax.set_title(\"Comparativa de precisión final\", fontsize=14)\n",
    "ax.bar_label(bars, fmt=\"%.3f\", padding=3)\n",
    "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Análisis de generalización ---\n",
    "print(\"📊 Evaluación de la generalización del modelo:\\n\")\n",
    "print(f\"▪ Diferencia Entrenamiento–Validación: {gap_train_val:+.2f}%\")\n",
    "print(f\"▪ Diferencia Entrenamiento–Test:       {gap_train_test:+.2f}%\")\n",
    "\n",
    "if abs(gap_train_test) < 2:\n",
    "    msg = \"Excelente generalización 💎 (modelo estable y sin overfitting).\"\n",
    "elif abs(gap_train_test) < 5:\n",
    "    msg = \"Buena generalización 👍 (ligero gap esperable en problemas reales).\"\n",
    "elif gap_train_test > 5:\n",
    "    msg = \"⚠️ Posible overfitting: el modelo rinde mejor en train que en test.\"\n",
    "else:\n",
    "    msg = \"⚠️ Posible underfitting: el modelo no llega a aprender bien los patrones.\"\n",
    "\n",
    "print(f\"\\n🔎 Diagnóstico: {msg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67115d",
   "metadata": {},
   "source": [
    "## 🧠 Interpretación de la gráfica de generalización\n",
    "\n",
    "La gráfica compara la **precisión (accuracy)** del modelo en los tres conjuntos de datos:\n",
    "\n",
    "- 🟩 **Entrenamiento (Train)** → mide cómo de bien el modelo aprende los patrones conocidos.  \n",
    "- 🟪 **Validación (Val)** → evalúa el rendimiento en datos no usados durante el aprendizaje (control del *overfitting*).  \n",
    "- 🟦 **Test** → mide la capacidad del modelo para generalizar a datos completamente nuevos.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Cómo interpretar las diferencias\n",
    "\n",
    "| Métrica | Significado | Interpretación |\n",
    "|:--------|:-------------|:---------------|\n",
    "| **Train alto y Val/Test similares** | El modelo aprende bien sin memorizar. | ✅ Buen equilibrio y generalización. |\n",
    "| **Train ≫ Val/Test (gap > 5%)** | El modelo memoriza los datos de entrenamiento. | ⚠️ *Overfitting* — mala generalización. |\n",
    "| **Train ≈ Val ≈ Test pero todos bajos** | El modelo no aprende patrones relevantes. | ⚠️ *Underfitting* — poca capacidad o datos insuficientes. |\n",
    "| **Val o Test ligeramente menor (2–5%)** | Diferencia esperable en la práctica. | 👍 Modelo estable y bien regularizado. |\n",
    "\n",
    "---\n",
    "\n",
    "### 📈 Qué observar en la gráfica\n",
    "\n",
    "- Si las barras de **Validación** y **Test** están **cercanas entre sí**, el modelo **generaliza correctamente**.  \n",
    "- Si la barra de **Entrenamiento** está muy por encima, el modelo **sobreajusta**.  \n",
    "- Si todas las barras están bajas, el modelo **no está aprendiendo** los patrones de forma efectiva.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 Gap de generalización\n",
    "\n",
    "La diferencia porcentual entre *Train* y *Test* indica el nivel de generalización:\n",
    "\n",
    "| Gap (`train - test`) | Diagnóstico |\n",
    "|:---------------------:|:-------------|\n",
    "| **< 2 %** | 💎 Excelente generalización |\n",
    "| **2–5 %** | 👍 Buena generalización |\n",
    "| **> 5 %** | ⚠️ Posible *overfitting* |\n",
    "| **Gap negativo grande** | ⚠️ *Underfitting* — el modelo rinde peor incluso en entrenamiento |\n",
    "\n",
    "---\n",
    "\n",
    "### 💬 En resumen\n",
    "\n",
    "> Un modelo **bien generalizado** mantiene un rendimiento similar entre *train*, *val* y *test*,  \n",
    "> lo que indica que ha aprendido **patrones reales** y no solo ha memorizado las imágenes de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a735fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 8: Curvas de pérdida y precisión (versión final) ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8-muted')\n",
    "\n",
    "epochs_range = range(1, len(history[\"train_loss\"]) + 1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# --- Pérdida ---\n",
    "ax[0].plot(epochs_range, history[\"train_loss\"], \"o-\", color=\"#1f77b4\", label=\"Entrenamiento\")\n",
    "ax[0].plot(epochs_range, history[\"val_loss\"], \"o--\", color=\"#ff7f0e\", label=\"Validación\")\n",
    "ax[0].set_title(\"Evolución de la pérdida\", fontsize=13)\n",
    "ax[0].set_xlabel(\"Época\"); ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].legend(frameon=False); ax[0].grid(ls=\"--\", alpha=0.6)\n",
    "\n",
    "# --- Precisión ---\n",
    "ax[1].plot(epochs_range, history[\"train_acc\"], \"o-\", color=\"#57c057\", label=\"Entrenamiento\")\n",
    "ax[1].plot(epochs_range, history[\"val_acc\"], \"o--\", color=\"#c662c1\", label=\"Validación\")\n",
    "ax[1].set_title(\"Evolución de la precisión\", fontsize=13)\n",
    "ax[1].set_xlabel(\"Época\"); ax[1].set_ylabel(\"Accuracy\")\n",
    "ax[1].legend(frameon=False); ax[1].grid(ls=\"--\", alpha=0.6)\n",
    "\n",
    "plt.suptitle(\"Curvas de entrenamiento del modelo\", fontsize=15, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"curvas_entrenamiento.png\", dpi=220, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"✅ Guardadas como: curvas_entrenamiento.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f533062a",
   "metadata": {},
   "source": [
    "# ü©∫ Clasificaci√≥n de Melanomas a partir de Im√°genes\n",
    "\n",
    "## üåë Introducci√≥n\n",
    "El **melanoma** es un tipo de c√°ncer de piel que se origina en los **melanocitos**, las c√©lulas encargadas de producir la melanina, el pigmento que da color a la piel, ojos y cabello.  \n",
    "Aunque representa un porcentaje peque√±o de los c√°nceres de piel, es el **m√°s agresivo** debido a su gran capacidad para invadir otros tejidos y producir met√°stasis.  \n",
    "La detecci√≥n temprana es fundamental, ya que aumenta considerablemente las posibilidades de un tratamiento exitoso y de supervivencia del paciente.  \n",
    "\n",
    "---\n",
    "\n",
    "## üîé Metodolog√≠a cl√≠nica: Regla ABCD\n",
    "En dermatolog√≠a se utiliza la **regla ABCD** como gu√≠a visual para identificar posibles melanomas:  \n",
    "\n",
    "- **A ‚Äì Asimetr√≠a**: los melanomas suelen tener formas irregulares; un lunar benigno suele ser sim√©trico.  \n",
    "- **B ‚Äì Bordes**: los melanomas presentan bordes difusos, dentados o irregulares, frente a los bordes definidos de los lunares normales.  \n",
    "- **C ‚Äì Color**: los melanomas pueden mostrar m√∫ltiples tonalidades (negro, marr√≥n, rojo, azul, blanco), mientras que los lunares benignos suelen ser uniformes.  \n",
    "- **D ‚Äì Di√°metro**: lesiones con un di√°metro superior a 6 mm se consideran sospechosas.  \n",
    "\n",
    "A esta regla a veces se a√±ade la **E ‚Äì Evoluci√≥n**, que hace referencia a cambios en el tama√±o, forma, color o la aparici√≥n de s√≠ntomas (picor, sangrado).  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivo del trabajo\n",
    "El objetivo de este proyecto es **desarrollar un modelo de aprendizaje autom√°tico capaz de clasificar im√°genes de lesiones cut√°neas** para distinguir entre melanomas y lesiones benignas.  \n",
    "Para ello:  \n",
    "- Se trabajar√° con un conjunto de im√°genes m√©dicas.  \n",
    "- Se aplicar√° un flujo de trabajo basado en la preparaci√≥n y preprocesamiento de datos, entrenamiento de modelos de deep learning y an√°lisis de resultados.  \n",
    "- Se evaluar√° el desempe√±o de los modelos con m√©tricas adecuadas, y se comparar√° con la metodolog√≠a cl√≠nica tradicional basada en la regla ABCD.  \n",
    "\n",
    "Este proyecto busca **apoyar el diagn√≥stico m√©dico mediante t√©cnicas computacionales**, aportando una herramienta complementaria a la pr√°ctica cl√≠nica.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb742632",
   "metadata": {},
   "source": [
    "# IMPORTACIONES Y RUTAS NECESARIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9be5a267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\proyectos\\Caso_aprendizaje-Melanomas\\data\\raw\\train exists: True\n",
      "D:\\proyectos\\Caso_aprendizaje-Melanomas\\data\\raw\\val exists: True\n",
      "D:\\proyectos\\Caso_aprendizaje-Melanomas\\data\\raw\\test exists: True\n"
     ]
    }
   ],
   "source": [
    "# IMPORTACIONES\n",
    "# Standard library\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Third-party\n",
    "import torch\n",
    "from PIL import Image, ImageOps\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "\n",
    "# RUTAS\n",
    "\n",
    "BASE_DIR = Path(\".\").resolve()\n",
    "DATA_DIR = Path(\"D:/proyectos/Caso_aprendizaje-Melanomas/data/raw\")\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "ALLOWED_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "TRAIN_DIR = DATA_DIR / \"train\"\n",
    "VAL_DIR   = DATA_DIR / \"val\"\n",
    "TEST_DIR  = DATA_DIR / \"test\"\n",
    "QUAR_DIR = DATA_DIR / \"_quarantine\"\n",
    "QUAR_DIR.mkdir(exist_ok=True)\n",
    "for p in (TRAIN_DIR, VAL_DIR, TEST_DIR): print(p, \"exists:\", p.exists())\n",
    "\n",
    "# Hiperpar√°metros\n",
    "CLASSES = 2\n",
    "BATCH   = 32\n",
    "ROWS = COLS = 224\n",
    "INPUT_CH = 3\n",
    "EPOCHS  = 20\n",
    "TEST_MAX_SAMPLES = 3000\n",
    "SEED    = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd1f98",
   "metadata": {},
   "source": [
    "## üìå ¬øPor qu√© separar en *train*, *validation* y *test*?\n",
    "\n",
    "En proyectos de *Machine Learning* es fundamental dividir los datos en diferentes conjuntos:\n",
    "\n",
    "- **Train (entrenamiento)**  \n",
    "  Se utiliza para que el modelo aprenda los patrones de las im√°genes.  \n",
    "\n",
    "- **Validation (validaci√≥n)**  \n",
    "  Sirve para ajustar hiperpar√°metros (n√∫mero de capas, tasa de aprendizaje, etc.) y comparar modelos sin mirar el *test*.  \n",
    "  üëâ Es una especie de \"examen parcial\": nos avisa si el modelo se est√° sobreajustando (*overfitting*) o si generaliza bien.  \n",
    "\n",
    "- **Test (prueba final)**  \n",
    "  Es el conjunto que se mantiene completamente aislado durante todo el desarrollo.  \n",
    "  üëâ Representa el \"examen final\" y nos da una estimaci√≥n real del rendimiento del modelo en datos nunca vistos.  \n",
    "\n",
    "‚úÖ En este caso (clasificaci√≥n de melanomas), separar en *train* y *val* es crucial porque:  \n",
    "- Ayuda a evitar *overfitting*, que ser√≠a muy peligroso si el modelo solo memoriza im√°genes.  \n",
    "- Permite evaluar de manera m√°s realista la capacidad de generalizaci√≥n antes de aplicarlo en un entorno cl√≠nico.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9444ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Benign</th>\n",
       "      <th>Malignant</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>5346</td>\n",
       "      <td>4752</td>\n",
       "      <td>10098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>943</td>\n",
       "      <td>838</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Benign  Malignant  Total\n",
       "train    5346       4752  10098\n",
       "val       943        838   1781\n",
       "test     1000       1000   2000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Funci√≥n para contar im√°genes por carpeta\n",
    "def count_images_in_dir(dir_path: Path):\n",
    "    if not dir_path.exists():\n",
    "        return {}\n",
    "    counts = {}\n",
    "    for cls_dir in dir_path.iterdir():\n",
    "        if cls_dir.is_dir():\n",
    "            n_imgs = sum(1 for f in cls_dir.rglob(\"*\") if f.suffix.lower() in ALLOWED_EXTS)\n",
    "            counts[cls_dir.name] = n_imgs\n",
    "    return counts\n",
    "\n",
    "# Recolectar conteos\n",
    "all_counts = {}\n",
    "for split in SPLITS:\n",
    "    split_dir = DATA_DIR / split\n",
    "    all_counts[split] = count_images_in_dir(split_dir)\n",
    "\n",
    "# Mostrar tabla\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(all_counts).fillna(0).astype(int).T\n",
    "df[\"Total\"] = df.sum(axis=1)\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c33059",
   "metadata": {},
   "source": [
    "## ‚ö° Uso de GPU en PyTorch\n",
    "\n",
    "Para acelerar el entrenamiento de los modelos, es importante usar la **GPU** en lugar de la **CPU** siempre que est√© disponible.  \n",
    "\n",
    "Con PyTorch podemos:  \n",
    "- Detectar autom√°ticamente si el sistema tiene una GPU con CUDA.  \n",
    "- Mover el **modelo** y los **tensores** al dispositivo adecuado (`cuda` o `cpu`).  \n",
    "- Asegurarnos de que todo el flujo de entrenamiento (inputs, labels, modelo, p√©rdidas) se ejecute en la GPU.  \n",
    "\n",
    "El siguiente c√≥digo hace esta detecci√≥n y muestra qu√© dispositivo se est√° utilizando.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe91ce1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponible: True\n",
      "GPU: NVIDIA GeForce MX250\n",
      "Tensor en: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# prueba r√°pida en GPU\n",
    "x = torch.randn(4096, 4096, device=device)\n",
    "y = x @ x\n",
    "print(\"Tensor en:\", y.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278bd94",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Dimensionado consistente de im√°genes\n",
    "\n",
    "Para que el modelo funcione con cualquier imagen, todas deben tener **mismo tama√±o** y **misma normalizaci√≥n**.\n",
    "\n",
    "- Tama√±o objetivo: `224x224` (est√°ndar para muchas CNN).\n",
    "- Estrategia:\n",
    "  - **Entrenamiento**: redimensionar + (opcional) aumentos de datos ligeros.\n",
    "  - **Validaci√≥n/Test**: solo redimensionar (sin aumentos).\n",
    "  - **Inferencia**: usar **exactamente** la misma trasformaci√≥n que `val/test`.\n",
    "\n",
    "> Nota: es preferible **transformar al vuelo** (con `DataLoader`) y **no sobrescribir** las im√°genes en disco. Si quieres un *export* a `data/processed/`, al final tienes una celda opcional para guardar las redimensionadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02cd49",
   "metadata": {},
   "source": [
    "## A) Limpieza r√°pida (corruptas + orientaci√≥n + RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bfe099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 10098 imgs, movidas a cuarentena: 0\n",
      "val: 1781 imgs, movidas a cuarentena: 0\n",
      "test: 2000 imgs, movidas a cuarentena: 0\n",
      "‚úÖ Limpieza b√°sica terminada (sin modificar im√°genes buenas).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clean_folder(split_dir: Path):\n",
    "    n_total=n_quar=0\n",
    "    for p in split_dir.rglob(\"*\"):\n",
    "        if p.suffix.lower() not in {\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\"}:\n",
    "            continue\n",
    "        n_total += 1\n",
    "        try:\n",
    "            with Image.open(p) as im:\n",
    "                im = ImageOps.exif_transpose(im)   # respeta la orientaci√≥n EXIF\n",
    "                if im.mode != \"RGB\":\n",
    "                    im = im.convert(\"RGB\")         # fuerza 3 canales\n",
    "                # No se guarda en disco: solo validamos que abre bien\n",
    "        except Exception as e:\n",
    "            n_quar += 1\n",
    "            shutil.move(str(p), QUAR_DIR / p.name)\n",
    "    print(f\"{split_dir.name}: {n_total} imgs, movidas a cuarentena: {n_quar}\")\n",
    "\n",
    "for split in [\"train\",\"val\",\"test\"]:\n",
    "    d = DATA_DIR / split\n",
    "    if d.exists():\n",
    "        clean_folder(d)\n",
    "print(\"‚úÖ Limpieza b√°sica terminada (sin modificar im√°genes buenas).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8d561",
   "metadata": {},
   "source": [
    "## B) Transforms coherentes (letterbox + resize + tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4963b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PadToSquare:\n",
    "    def __init__(self, fill=0): self.fill = fill\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        s = max(w, h)\n",
    "        pad_left  = (s - w) // 2\n",
    "        pad_right = s - w - pad_left\n",
    "        pad_top   = (s - h) // 2\n",
    "        pad_bottom= s - h - pad_top\n",
    "        return TF.pad(img, [pad_left, pad_top, pad_right, pad_bottom], fill=self.fill)\n",
    "\n",
    "# >>> Si vas a usar TRANSFER LEARNING (recomendado):\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    PadToSquare(fill=0),\n",
    "    transforms.Resize((ROWS, COLS)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05,0.05)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "eval_tfms = transforms.Compose([\n",
    "    PadToSquare(fill=0),\n",
    "    transforms.Resize((ROWS, COLS)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = datasets.ImageFolder(DATA_DIR / \"train\", transform=train_tfms)\n",
    "val_ds   = datasets.ImageFolder(DATA_DIR / \"val\",   transform=eval_tfms) if (DATA_DIR / \"val\").exists() else None\n",
    "test_ds  = datasets.ImageFolder(DATA_DIR / \"test\",  transform=eval_tfms) if (DATA_DIR / \"test\").exists() else None\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=(device.type==\"cuda\"))\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=(device.type==\"cuda\")) if val_ds else None\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=(device.type==\"cuda\")) if test_ds else None\n",
    "\n",
    "xb, yb = next(iter(train_dl))\n",
    "print(\"Batch:\", xb.shape)  # [B, 3, 224, 224]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9384e0",
   "metadata": {},
   "source": [
    "## C) Inferencia de una imagen (mismo pipeline que val/test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
